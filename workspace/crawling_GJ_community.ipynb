{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 테스트\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[39m# 페이지 내용을 처리하는 코드 작성\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \n\u001b[0;32m     15\u001b[0m     \u001b[39m# 예를 들어, 페이지 내의 모든 제목 가져오기\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[39m#titles = soup.find_all('span', class_='tit')\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     titles \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtit\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mfor\u001b[39;00m title \u001b[39min\u001b[39;00m titles:\n\u001b[0;32m     19\u001b[0m         \u001b[39mprint\u001b[39m(title\u001b[39m.\u001b[39mtext)\n\u001b[0;32m     20\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# 가져올 페이지의 범위 설정 (예: 1부터 5페이지까지)\n",
    "start_page = 1\n",
    "end_page = 142\n",
    "\n",
    "for page_number in range(start_page, end_page + 1):\n",
    "    url = f'https://www.gwangjin.go.kr/mayor/cvpl/reqst/list.do?cvplKndCd=DSTLDR&menuNo=500015&pageIndex={page_number}'  # 페이지 번호를 포함한 URL 생성\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # 페이지 내용을 처리하는 코드 작성\n",
    "        \n",
    "        # 예를 들어, 페이지 내의 모든 제목 가져오기\n",
    "        #titles = soup.find_all('span', class_='tit')\n",
    "        titles = soup.find('a', class_='tit')\n",
    "        \n",
    "        for title in titles:\n",
    "            print(title.text)\n",
    "    else:\n",
    "        print(f'Failed to fetch the webpage: {url}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac31577eb9c5ba88a4b4e3524678c8d3841048a82d1df3a8c39a7cbe579b0bf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
